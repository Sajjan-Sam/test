<div align="center">

# ğŸ­ Facial Emotion Recognition System

### *Decoding Human Emotions Through Computer Vision & Machine Learning*

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-Latest-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org)
[![DeepFace](https://img.shields.io/badge/DeepFace-Enabled-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://github.com/serengil/deepface)
[![Colab](https://img.shields.io/badge/Google%20Colab-Ready-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com)

<br/>

<img src="https://raw.githubusercontent.com/catppuccin/catppuccin/main/assets/palette/macchiato.png" width="600"/>

<br/>

**Presented by Advanced Signal and Image Processing Lab (ASIP Lab)**  
*Dept. of Data Science and Engineering, IISER Bhopal*

---

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [How It Works](#-how-it-works) â€¢ [Models](#-model-comparison) â€¢ [Results](#-results)

</div>

---

## ğŸŒŸ Features

<table>
<tr>
<td width="50%">

### ğŸ” Face Detection
- **Haar Cascade** - Robust frontal face detection
- **LBP Cascade** - Fast & lightweight alternative
- Multi-face detection support
- Real-time processing capability

</td>
<td width="50%">

### ğŸ§  Emotion Analysis
- **7 Core Emotions**: Happy, Sad, Angry, Surprise, Fear, Disgust, Neutral
- **2 Extended States**: Depressed*, Confused* (proxy detection)
- Multiple ML algorithms compared
- Deep learning powered analysis

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install opencv-python numpy matplotlib scikit-learn deepface seaborn
```

### Run Face Detection

```python
import cv2

# Load cascade classifiers
haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')
lbp_cascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml')

# Detect faces
img = cv2.imread('your_image.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
faces = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

print(f"Detected {len(faces)} face(s)")
```

### Run Emotion Detection (DeepFace)

```python
from deepface import DeepFace

result = DeepFace.analyze(
    img_path="your_image.jpg",
    actions=["emotion"],
    detector_backend="opencv"
)

print(f"Dominant emotion: {result[0]['dominant_emotion']}")
```

---

## ğŸ”¬ How It Works

### The Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Image     â”‚â”€â”€â”€â–¶â”‚  Preprocessing  â”‚â”€â”€â”€â–¶â”‚   Feature    â”‚â”€â”€â”€â–¶â”‚    ML      â”‚
â”‚   Input     â”‚    â”‚  & Face Detect  â”‚    â”‚  Extraction  â”‚    â”‚ Classifier â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                       â”‚                  â”‚
                          â–¼                       â–¼                  â–¼
                    â€¢ Grayscale              â€¢ HoG (edges)      â€¢ SVM
                    â€¢ Scaling                â€¢ LBP (texture)    â€¢ Random Forest
                    â€¢ Denoising                                 â€¢ KNN
                                                                â€¢ Decision Tree
```

### Feature Extraction Techniques

<details>
<summary><b>ğŸ“ Histogram of Oriented Gradients (HoG)</b></summary>

HoG captures structural information by analyzing edge orientations:

| Parameter | Value | Purpose |
|-----------|-------|---------|
| Orientations | 9 | Number of gradient direction bins |
| Pixels per Cell | 8Ã—8 | Local region size |
| Cells per Block | 2Ã—2 | Normalization window |
| **Output** | **1764 features** | Compressed representation |

```python
from skimage.feature import hog

hog_features = hog(image, orientations=9, pixels_per_cell=(8,8), 
                   cells_per_block=(2,2), visualize=False)
```

> ğŸ’¡ **Why HoG?** Captures macro-structure like eyebrow curves and mouth shapes

</details>

<details>
<summary><b>ğŸ”² Local Binary Patterns (LBP)</b></summary>

LBP describes micro-textures and is robust to illumination changes:

| Parameter | Value | Purpose |
|-----------|-------|---------|
| P (Points) | 8 | Neighbor sampling points |
| R (Radius) | 1 | Circular radius |
| Method | Uniform | Reduces feature dimensions |
| **Output** | **59 features** | Histogram of patterns |

```python
from skimage.feature import local_binary_pattern

lbp = local_binary_pattern(image, P=8, R=1, method='uniform')
lbp_hist = np.histogram(lbp, bins=59, range=(0, 59))[0]
```

> ğŸ’¡ **Why LBP?** Captures skin texture, wrinkles, and fine facial details

</details>

---

## ğŸ“Š Model Comparison

We trained and evaluated **4 machine learning algorithms** on **1,575 images** across **7 emotion classes**:

| Model | Accuracy | Training Time | Strengths |
|-------|----------|---------------|-----------|
| ğŸ¥‡ **SVM (RBF)** | **44.13%** | Medium | Best at finding optimal decision boundaries |
| ğŸ¥ˆ Random Forest | 36.51% | Fast | Ensemble voting, handles noise well |
| ğŸ¥‰ KNN (k=5) | 32.70% | Very Fast | Simple, instance-based learning |
| Decision Tree | 22.86% | Very Fast | Interpretable, but prone to overfitting |

```
                    Model Performance Comparison
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ SVM          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  44.1%   â”‚
    â”‚ Random Forestâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  36.5%   â”‚
    â”‚ KNN          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  32.7%   â”‚
    â”‚ Decision Treeâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  22.9%   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why These Accuracies?

> Traditional ML on raw features faces challenges:
> - Subtle differences between emotions (e.g., sad vs. neutral)
> - Limited training data (1,575 images)
> - High intra-class variation
> 
> **For production use**, consider deep learning approaches like DeepFace which achieve **90%+ accuracy**

---

## ğŸ¯ Extended Emotion Detection

Beyond the 7 base emotions, we compute **proxy scores** for complex states:

```python
# Depressed: high sad + neutral, low happy
depressed = clamp01(0.60 * sad + 0.40 * neutral - 0.30 * happy)

# Confused: uncertainty mixture with surprise/fear
confused = clamp01(0.45 * surprise + 0.35 * fear + 0.20 * neutral - 0.20 * happy)
```

### Sample Output

```
Face 1 expanded scores (top 6):
â”œâ”€â”€ happy     : 96.3% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”œâ”€â”€ neutral   :  3.7% â–ˆ
â”œâ”€â”€ surprise  :  0.0% 
â”œâ”€â”€ sad       :  0.0% 
â”œâ”€â”€ fear      :  0.0% 
â””â”€â”€ angry     :  0.0% 
```

---

## ğŸ“ˆ Results

### Confusion Matrix Analysis

```
                    Predicted Emotion
              â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
              â”‚Angry â”‚Disg. â”‚Fear  â”‚Happy â”‚Neut. â”‚ Sad  â”‚Surp. â”‚
        â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
 Actual â”‚Angryâ”‚  2   â”‚  0   â”‚  3   â”‚  5   â”‚  12  â”‚  11  â”‚  6   â”‚
        â”‚Disg.â”‚  1   â”‚  3   â”‚  2   â”‚  3   â”‚  4   â”‚  5   â”‚  4   â”‚
        â”‚Fear â”‚  2   â”‚  0   â”‚  1   â”‚  6   â”‚  12  â”‚  11  â”‚  6   â”‚
        â”‚Happyâ”‚  3   â”‚  1   â”‚  1   â”‚  43  â”‚  4   â”‚  3   â”‚  5   â”‚
        â”‚Neut.â”‚  3   â”‚  0   â”‚  3   â”‚  8   â”‚  26  â”‚  10  â”‚  5   â”‚
        â”‚ Sad â”‚  2   â”‚  1   â”‚  2   â”‚  10  â”‚  12  â”‚  19  â”‚  7   â”‚
        â”‚Surp.â”‚  1   â”‚  0   â”‚  0   â”‚  15  â”‚  7   â”‚  6   â”‚  29  â”‚
        â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

### Key Metrics Explained

| Metric | Formula | What It Tells Us |
|--------|---------|------------------|
| **Precision** | TP / (TP + FP) | "When model says Happy, is it right?" |
| **Recall** | TP / (TP + FN) | "Does model find ALL Happy faces?" |
| **F1-Score** | 2 Ã— (P Ã— R) / (P + R) | Balanced measure of both |

---

## ğŸ› ï¸ Project Structure

```
ğŸ“ facial-emotion-recognition/
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â”œâ”€â”€ face_detection.ipynb      # Haar & LBP face detection
â”‚   â”œâ”€â”€ emotion_ml.ipynb          # Traditional ML approach
â”‚   â””â”€â”€ emotion_deepface.ipynb    # Deep learning approach
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ haarcascade_frontalface_alt.xml
â”‚   â”œâ”€â”€ lbpcascade_frontalface.xml
â”‚   â””â”€â”€ test_images/
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ result_haar.jpg
â”‚   â””â”€â”€ result_lbp.jpg
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ”— Quick Links

| Resource | Link |
|----------|------|
| ğŸ““ Emotion Detection Colab | [sorts.pro/emotion](https://sorts.pro/emotion) |
| ğŸ““ Face Detection Colab | [sorts.pro/face](https://sorts.pro/face) |
| ğŸ““ Face + Emotion Colab | [sorts.pro/emotionface](https://sorts.pro/emotionface) |

---

## ğŸ“š References & Theory

<details>
<summary><b>Click to expand technical references</b></summary>

### Cascade Classifiers
- **Haar Features**: Viola-Jones algorithm using integral images for rapid feature computation
- **LBP Features**: Computationally simpler alternative with similar detection accuracy

### Machine Learning Models
- **SVM**: Finds optimal hyperplane using kernel trick (RBF kernel)
- **Random Forest**: Ensemble of 100 decision trees with majority voting
- **KNN**: Classification based on k=5 nearest neighbors in feature space
- **Decision Tree**: Recursive partitioning with max_depth=15

### Deep Learning
- **DeepFace**: Pre-trained CNN achieving state-of-the-art accuracy on FER benchmarks

</details>

---

## ğŸ‘¥ Team

<div align="center">

**Advanced Signal and Image Processing Lab (ASIP Lab)**

*Department of Data Science and Engineering*  
*Indian Institute of Science Education and Research (IISER) Bhopal*

| Role | Name |
|------|------|
| PI | Dr. Samiran Das |
| Presenter | Mr. Sajjan Singh |
| Presenter | Mr. Ramen Ghosh |


</div>

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

---

<div align="center">

### â­ Star this repo if you found it helpful!

<br/>

Made with â¤ï¸ by Sajjan Singh from ASIP Lab, IISER Bhopal

<br/>

[![forthebadge](https://forthebadge.com/images/badges/built-with-science.svg)](https://forthebadge.com)
[![forthebadge](https://forthebadge.com/images/badges/powered-by-coffee.svg)](https://forthebadge.com)

</div>
